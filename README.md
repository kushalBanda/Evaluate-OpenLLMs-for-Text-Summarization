# Evaluate-OpenLLMs-for-Text-Summarization

### Assignment: Evaluate OpenLLMs for Text Summarization
#### Objective:
Compare at least three OpenLLMs on a text summarization task and recommend the best model based on performance metrics.

Steps:
* Task Definition: Define the text summarization context (e.g., news articles).
* Dataset: Use a dataset with articles and their summaries.
* Model Selection: Pick at least three OpenLLMs.
* Implementation: Implement text summarization for each model.
* Metrics: Use ROUGE scores for performance evaluation.
* Evaluation: Apply metrics to each model.
* Analysis: Summarize performance in a table.
* Recommendation: Pick the best model and justify your choice.

Deliverables:
* Python scripts for each OpenLLM implementation.
* Table summarizing performance metrics.
* Final recommendation report.
* Evaluation Criteria:
    * Efficiency and quality of code
    * Accuracy of analysis
    * Proper use of metrics
* Clarity in the final report
